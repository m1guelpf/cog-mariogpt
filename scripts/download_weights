#!/usr/bin/env python

from predict import MODEL_CACHE, MODEL_ID
import os
import shutil
import sys

from transformers import AutoModelWithLMHead, AutoTokenizer

MODEL_ID = "shyamsn97/Mario-GPT2-700-context-length"
MODEL_CACHE = "transformers-cache"

# append project directory to path so predict.py can be imported
sys.path.append('.')

if os.path.exists(MODEL_CACHE):
    shutil.rmtree(MODEL_CACHE)
os.makedirs(MODEL_CACHE, exist_ok=True)

model = AutoModelWithLMHead.from_pretrained(
    MODEL_ID, add_cross_attention=True, cache_dir=MODEL_CACHE,
)
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, add_cross_attention=True, cache_dir=MODEL_CACHE,)
