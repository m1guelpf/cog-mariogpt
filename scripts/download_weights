#!/usr/bin/env python

import os
from transformers import AutoModelWithLMHead, AutoTokenizer, AutoModel

os.environ['TRANSFORMERS_CACHE'] = '/src/cache'
MODEL_ID = "shyamsn97/Mario-GPT2-700-context-length"

print("Downloading model...")
model = AutoModelWithLMHead.from_pretrained(
    MODEL_ID, add_cross_attention=True,
)
print("Downloading tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, add_cross_attention=True)

print("Downloading Bart...")
feature_extractor = AutoModel.from_pretrained("facebook/bart-base")
