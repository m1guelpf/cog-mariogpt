#!/usr/bin/env python

import os
from transformers import AutoModelWithLMHead, AutoTokenizer, AutoConfig

os.environ['TRANSFORMERS_CACHE'] = '/src/cache'
MODEL_ID = "shyamsn97/Mario-GPT2-700-context-length"

model = AutoModelWithLMHead.from_pretrained(
    MODEL_ID, add_cross_attention=True,
)
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, add_cross_attention=True)
feature_extractor = AutoConfig.from_pretrained("facebook/bart-base", _from_pipeline='feature-extraction')
